{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b4241a-d7e4-4a6a-b0ce-95a6114e4252",
   "metadata": {},
   "source": [
    "# DS Hackathon\n",
    "## Image Segmentation\n",
    "#### Team A\n",
    "Challenge Description:\n",
    "Your team must design a segmentation model which detects miscellaneous defects, learns from a weakly\n",
    "labeled dataset, and works on images whose characteristics are unknown at development time.\n",
    "Detecting defects in the industry is one of the most important tasks in visual inspection and it is still an\n",
    "active topic in computer vision applications research. The dataset and problem presented here are a good\n",
    "introduction to get an idea of the type of challenges that are faced in Automatic visual defect detection in\n",
    "the industry.\n",
    "The dataset in this challenge consists of different anomalies or indications in a variety of background\n",
    "textures. The dataset is synthetic, but it is based on real indications, it was originally created for a\n",
    "competition at the 2007 symposium of the DAGM, and it is publicly available from the University of\n",
    "Heidelberg website.\n",
    "Be aware that we have slightly modified the images for this challenge, and that they are the only ones that\n",
    "you should use as input. However, techniques as data augmentation are encouraged.\n",
    "\n",
    "[Kaggle Competition Link](https://www.kaggle.com/t/da322bd83be74d8e8fa27dd16d8956c0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160bfa3-27f1-43aa-8769-92ee24b513ea",
   "metadata": {},
   "source": [
    "This notebook is based on the Simple Cell Segmentation with Keras and U-Net notebook on kagle created by Marsh\n",
    "https://www.kaggle.com/vbookshelf/simple-cell-segmentation-with-keras-and-u-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba991e-52e7-4dd2-91d5-bdc8f3fd6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c432bc0d-efd8-4436-9f74-89357c4556dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure images dimensions\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "NUM_TEST_IMAGES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5dfd5-18ec-4300-a834-807116217308",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca01f57-f6f0-49fc-b9ec-7fcd2cc86994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our data \n",
    "\n",
    "img_list = os.listdir('D:/Augmentation/Image')\n",
    "mask_list = os.listdir('D:/Augmentation/Mask')\n",
    "\n",
    "# create a dataframe\n",
    "df_images = pd.DataFrame(img_list, columns=['image_id'])\n",
    "\n",
    "# filter out the non image file that's called .htaccess\n",
    "df_images = df_images[df_images['image_id'] != '.htaccess']\n",
    "\n",
    "# Keep in mind images and masks have the same file names.\n",
    "\n",
    "def check_for_mask(x):\n",
    "    if x in mask_list:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'no'\n",
    "    \n",
    "# create a new column called 'has_mask'\n",
    "df_images['has_mask'] = df_images['image_id'].apply(check_for_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5feca20-9a65-4ce0-b092-dd9a18b0193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfefc1-28a0-4976-b84f-eca2b93796ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_masks = df_images[df_images['has_mask'] == 'yes']\n",
    "\n",
    "# create a new column called mask_id that is just a copy of image_id\n",
    "df_masks['mask_id'] = df_masks['image_id']\n",
    "\n",
    "df_masks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245c143-9e5d-4de1-9d1b-64c00c03aa44",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454eccb-6ae8-4cbd-83e1-f7d39e668b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test set\n",
    "df_test = df_masks.sample(NUM_TEST_IMAGES, random_state=101)\n",
    "\n",
    "# Reset the index.\n",
    "# This is so that we can use loc to access mask id's later.\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# create a list of test images\n",
    "test_images_list = list(df_test['image_id'])\n",
    "\n",
    "\n",
    "# Select only rows that are not part of the test set.\n",
    "# Note the use of ~ to execute 'not in'.\n",
    "df_masks = df_masks[~df_masks['image_id'].isin(test_images_list)]\n",
    "\n",
    "print(df_masks.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647f52b-5452-4c46-b8a1-4255ee15d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists of images and their masks.\n",
    "image_id_list = list(df_masks['image_id'])\n",
    "mask_id_list = list(df_masks['mask_id'])\n",
    "test_id_list = list(df_test['image_id'])\n",
    "\n",
    "# Create empty arrays\n",
    "\n",
    "X_train = np.zeros((len(image_id_list), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "Y_train = np.zeros((len(image_id_list), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "X_test = np.zeros((NUM_TEST_IMAGES, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b3049-31e2-4170-8989-5374e57a818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "for i, image_id in enumerate(image_id_list):\n",
    "    \n",
    "    path_image = 'D:/Augmentation/Image/' + image_id\n",
    "    \n",
    "    # read the image using skimage\n",
    "    image = imread(path_image)\n",
    "    \n",
    "    \n",
    "    # resize the image\n",
    "    image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    \n",
    "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    \n",
    "    # insert the image into X_train\n",
    "    X_train[i] = image\n",
    "    \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459246b-eed2-4399-bcbe-bef986eb85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train\n",
    "for i, mask_id in enumerate(mask_id_list):\n",
    "    \n",
    "    path_mask = 'D:/Augmentation/Mask/' + mask_id\n",
    "    \n",
    "    # read the image using skimage\n",
    "    mask = imread(path_mask)\n",
    "    \n",
    "    \n",
    "    # resize the image\n",
    "    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    \n",
    "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    \n",
    "    # insert the image into Y_Train\n",
    "    Y_train[i] = mask\n",
    "\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ec959-ad02-4620-86db-2704b4fa375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test\n",
    "\n",
    "for i, image_id in enumerate(test_id_list):\n",
    "    \n",
    "    path_image = 'D:/Augmentation/Image/' + image_id\n",
    "    \n",
    "    # read the image using skimage\n",
    "    image = imread(path_image)\n",
    "    \n",
    "    # resize the image\n",
    "    image = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    \n",
    "    # use np.expand dims to add a channel axis so the shape becomes (IMG_HEIGHT, IMG_WIDTH, 1)\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    \n",
    "    # insert the image into X_test\n",
    "    X_test[i] = image\n",
    "    \n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22304e21-0f9f-43de-bea4-b9e44efc231f",
   "metadata": {},
   "source": [
    "## Architecture U-net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fbea2-31a3-470b-afe4-fa48c9efba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd4400-7901-4108-a783-d3a1dcd2a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\n",
    "\n",
    "\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afec22fa-6c13-46b7-86af-780aec835d40",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49819ad2-4850-4579-9ed0-6b3f646b947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save model\n",
    "filepath = \"model.h5\"\n",
    "\n",
    "# Training parameters \n",
    "earlystopper = EarlyStopping(patience=10, verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [earlystopper, checkpoint]\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=120, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a1f06-d72c-4d55-8d18-a0b9b3f8b5e4",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43ac4d-b311-48d1-bc6e-fd85c3c7831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6ea9b-57c2-4c43-b99b-1b9b1dc4c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the predictions\n",
    "\n",
    "preds_test_thresh = (test_preds >= 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48dc8f-a040-40ca-95eb-1652240b3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a thresholded mask\n",
    "test_img = preds_test_thresh[3, :, :, 0]\n",
    "\n",
    "plt.imshow(test_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0fcc0-1904-42bd-8d2b-3a26d80b357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the canvas for the subplots\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axis('Off')\n",
    "\n",
    "\n",
    "# == row 1 ==\n",
    "\n",
    "# image\n",
    "plt.subplot(3,3,1)\n",
    "test_image = X_test[1, :, :, 0]\n",
    "plt.imshow(test_image)\n",
    "plt.title('Test Image', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "# true mask\n",
    "plt.subplot(3,3,2)\n",
    "mask_id = df_test.loc[1,'mask_id']\n",
    "path_mask = 'D:/Augmentation/Mask/' + mask_id\n",
    "mask = imread(path_mask)\n",
    "mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title('True Mask', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "# predicted mask\n",
    "plt.subplot(3,3,3)\n",
    "test_mask = preds_test_thresh[1, :, :, 0]\n",
    "plt.imshow(test_mask, cmap='gray')\n",
    "plt.title('Pred Mask', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "# == row 2 ==\n",
    "\n",
    "# image\n",
    "plt.subplot(3,3,4)\n",
    "test_image = X_test[2, :, :, 0]\n",
    "plt.imshow(test_image)\n",
    "plt.title('Test Image', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "# true mask\n",
    "plt.subplot(3,3,5)\n",
    "mask_id = df_test.loc[2,'mask_id']\n",
    "path_mask = 'D:/Augmentation/Mask/' + mask_id\n",
    "mask = imread(path_mask)\n",
    "mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title('True Mask', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "# predicted mask\n",
    "plt.subplot(3,3,6)\n",
    "test_mask = preds_test_thresh[2, :, :, 0]\n",
    "plt.imshow(test_mask, cmap='gray')\n",
    "plt.title('Pred Mask', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "# == row 3 ==\n",
    "\n",
    "# image\n",
    "plt.subplot(3,3,7)\n",
    "test_image = X_test[8, :, :, 0]\n",
    "plt.imshow(test_image)\n",
    "plt.title('Test Image', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "# true mask\n",
    "plt.subplot(3,3,8)\n",
    "mask_id = df_test.loc[8,'mask_id']\n",
    "path_mask = 'D:/Augmentation/Mask/' + mask_id\n",
    "mask = imread(path_mask)\n",
    "mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title('True Mask', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "# predicted mask\n",
    "plt.subplot(3,3,9)\n",
    "test_mask = preds_test_thresh[8, :, :, 0]\n",
    "plt.imshow(test_mask, cmap='gray')\n",
    "plt.title('Pred Mask', fontsize=14)\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8cb6a8-c72a-4479-b58d-d7d0e3a8bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "\n",
    "history.history.keys()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c73481f-1926-4da9-85fc-fc9ecc21878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = tf.keras.metrics.MeanIoU(num_classes=3)\n",
    "# m.update_state(model.predict(X_train), Y_train)\n",
    "# m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40ddd1-97b9-4898-b364-c1e07e116f58",
   "metadata": {},
   "source": [
    "## Predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8704d3f-5f71-457b-b5cb-4aa68c3d2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba409da4-0bdc-4c3b-8aa1-8b1b17d33517",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.zeros((len(os.listdir('Test/Image')), IMG_HEIGHT, IMG_WIDTH,1), dtype=np.uint8)\n",
    "\n",
    "for i, image_id in enumerate(os.listdir('Test/Image')):\n",
    "    \n",
    "    path_image = 'Test/Image/' + image_id\n",
    "    \n",
    "    # read the image using skimage\n",
    "    image = imread(path_image)\n",
    "    \n",
    "    # resize the image\n",
    "    image = resize(image, (IMG_HEIGHT, IMG_WIDTH,1), mode='constant', preserve_range=True)\n",
    "    \n",
    "    \n",
    "    # add image to X_val\n",
    "    X_val[i] = image\n",
    "    \n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f88a4f-ebc3-48a3-8822-dc3577757efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc2e07d-e5db-43a5-9aa0-5fffae728aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val_thresh = (val_preds >= 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b675fc73-16cb-4bcd-b4a8-019674904786",
   "metadata": {},
   "source": [
    "## Run length encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca868c-cdbf-4d92-bc0e-97cb6810af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function retrieve from https://www.kaggle.com/leahscherschel/run-length-encoding\n",
    "# Modified to return data as string \n",
    "\n",
    "def rle_encoding(x):\n",
    "    '''\n",
    "    x: numpy array of shape (height, width), non 0 - mask, 0 - background\n",
    "    Returns run length as string\n",
    "    '''\n",
    "    run_lengths = []\n",
    "    for i in range(len(x)):\n",
    "        run_lengths.append([])\n",
    "    current = 0\n",
    "    count = 0\n",
    "    start = 0\n",
    "    flat = x.T.flatten()\n",
    "    for i in range(len(flat)):\n",
    "        dot = flat[i]\n",
    "        if dot == 0:\n",
    "            if current == 0:\n",
    "                continue\n",
    "            else:\n",
    "                run_lengths[current-1].extend([start, count])\n",
    "                current = 0\n",
    "                count = 0\n",
    "                start = 0\n",
    "        else:\n",
    "            if dot == current:\n",
    "                count += 1\n",
    "            elif count != 0:\n",
    "                run_lengths[current-1].extend([start, count])\n",
    "                current = 0\n",
    "                count = 0\n",
    "                start = 0\n",
    "            else:\n",
    "                start = i\n",
    "                current = dot\n",
    "                count += 1\n",
    "    return ' '.join(str(x) for x in run_lengths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5603c9-5119-4db7-9168-a9ee10852e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in a CSV images numbers and RLE encoded values\n",
    "with open('test.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    header = ['ImageId', 'EncodedPixels']\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for i, j in enumerate(os.listdir('Test/Image')):\n",
    "        print(i)\n",
    "        img = np.array(preds_val_thresh[i,:,:,0])\n",
    "        img = resize(img, (512, 512), mode='constant', preserve_range=True)\n",
    "        rle_encoded = rle_encoding(img.astype('uint16'))\n",
    "\n",
    "        data = [j[:-4], rle_encoded]\n",
    "\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18fa145-396a-41f3-a2d7-4c5b1c2cf1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
